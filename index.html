<!doctype html>
<html lang="en">
  <head>

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Pre-Doctoral Researcher, Google Research India">
    <meta name="author" content="Rishubh Singh">
    <meta name="theme-color" content="#222222">

    <link rel="apple-touch-icon" sizes="180x180" href="images/favicon_io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/favicon_io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/favicon_io/favicon-16x16.png">

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    <link rel="stylesheet" href="assets/style-2.css">

    <title>Rishubh Singh</title>
  </head>
  <body>
    <!-- <h1>Hello, world!</h1> -->
    <div class="container pt-5 allstuffp">
        <div class="row pt-5 allstuff">
            <div class="col-md-4 pt-5">
                <div class="fixed-posi">
                <p class="name">Rishubh Singh</p>
                <img src="images/photo1.jpeg" class="profilepic pt-3 pb-2">
                <div class="pt-5 menur"><a class="menulink" target="_blank" href="mailto:rishubh@google.com"><i class="fa fa-envelope fa-1x headtag"></i> rishubh@google.com</a></div>
                <div class=""><a class="menulink" target="_blank" href="assets/Rishubh_PhD_Resume.pdf"><i class="ai ai-cv-square ai-1x headtag"></i> curriculum vitae</a></div>
                <div class=""><a class="menulink" target="_blank" href="https://scholar.google.com/citations?user=HXdEK8gAAAAJ&hl=en"><i class="ai ai-google-scholar ai-1x headtag"></i> google scholar</a></div>
                <div class=""><a class="menulink" target="_blank" href="https://github.com/rishubhsingh"><i class="fab fa-github-square fa-1x headtag"></i> github</a></div>
                <div class=""><a class="menulink" target="_blank" href="https://www.linkedin.com/in/rishubh-singh-a95696aa/"><i class="fab fa-linkedin fa-1x headtag"></i> linkedin</a></div>
                <div class=""><a class="menulink" target="_blank" href="https://twitter.com/rishubhsingh135"><i class="fab fa-twitter-square fa-1x headtag"></i> twitter</a></div>
                

                <!-- <div class="pt-5">usercontext</div> -->
                <!-- <div class="">travel history</div> -->
                <!-- <div class="">this template</div> -->
                </div>
            </div>
            <div class="col-md-8 pt-5 about">
                 I am a <a class="in-text" href="https://research.google/people/RishubhSingh/" target="_blank">Pre-Doctoral Researcher</a>
                 at <a class="in-text" href="https://research.google/teams/india-research-lab/"
                     target="_blank">Google Research India</a>, where I work with <a class="in-text"
                     href="https://sites.google.com/site/pshenoyuw/" target="_blank">Dr. Pradeep Shenoy</a> on cognitively inspired deep neural networks.
                     <br><br>
                     I am interested in working on problems at the intersection of Deep Learning and Neuroscience
                      with applications in Vision. My research goal is the comparative understanding of primate and machine vision to create robust and interepretable <b>cognitively-inspired ML models</b>.<br> <br>

                At Google, I have had opportunity to work on projects in collaboration with <a class="in-text" href="https://ravika.github.io/" target="_blank">Prof. Ravi Kiran Sarvadevabhatla</a> (IIIT Hyderabad),
                <a class="in-text" href="https://cogsci.ucsd.edu/~desa/" target="_blank">Prof. Virginia De Sa</a> (UC San Diego), 
                <a class="in-text" href="https://home.cs.colorado.edu/~mozer/index.php" target="_blank">Dr. Mike Mozer</a> (Google Research) and 
                <a class="in-text" href="https://robustml.is.mpg.de/" target="_blank">Prof. Wieland Brendel</a> (University of Tubingen). <br><br>

                 I have been fortunate in pursuing my master's thesis at <a class="in-text" href="http://www.iitd.ac.in" target="_blank">Indian Institue of Technology, Delhi</a> under
                 the guidance of <a class="in-text" href="https://web.iitd.ac.in/~sumeet/" target="_blank">Prof. Sumeet 
                     Agrawal</a>. Before that, I spent the Summers of 2018 and 2017 at Google, Mountain View as a Software Engineering Intern.
                     I spent the fall semester of 2016 as an exchange student at <a class="in-text" href="https://www.kth.se/" target="_blank">KTH Royal Institue of Technology</a>. <br><br>

                 I was awarded the <a class="in-text" href="https://ird.iitd.ac.in/content/summer-undergraduate-research-award-sura" target="_blank">
                    Summer Undergraduate Research Award</a> for successfully parallezing a parallel program verification engine INSPECT with upto 5x gains in runtime
                 under <a class="in-text" href="https://subodhvsharma.github.io/" target="_blank">Prof. Subodh Sharma</a> during the Summer and Fall of 2016. <br><br>

                 I graduated with a Dual Degree, Bachelor and Master of Technology in Computer Science and Engineering from <a class="in-text"
                     href="http://www.iitd.ac.in" target="_blank">Indian Institute of Technology, Delhi</a>, India in 2019. For more
                 details, check my <a class="in-text" href="assets/Rishubh_PhD_Resume.pdf" target="_blank">CV</a> or send me
                 an <a class="in-text" href="mailto:rishubh@google.com">email</a>. <br><br>


                 <p class="header pt-5">Publications</p>
                 <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="projecttitle">Robustifying Deep Vision Models Through Shape Sensitization</span><br>
                        Aditay Tripathi, <span class="thisauthor"><b>Rishubh Singh</b></span>, Anirban Chakraborty, Pradeep Shenoy<br>
                        <span class="conf"><em>ArXiv Preprint</em> </span> <br>
                        <a class="tag" href="https://arxiv.org/abs/2211.07277" target="_blank">abstract</a><span class="tagsep"> | </span>
                        <a class="tag" href="https://arxiv.org/pdf/2211.07277.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                        <a class="tag" href="cites/robustifying.bib" target="_blank">cite</a>
                    </p>

                    <p class="paper my-2 pl-2">
                        <span class="projecttitle">FLOAT: Factorized Learning of Object Attributes for Improved Multi-object Multi-part Scene Parsing</span><br>
                        <span class="thisauthor"><b>Rishubh Singh</b></span>, Pranav Gupta, Pradeep Shenoy, Ravi Kiran Sarvadevabhatla <br>
                        <span class="conf"><em>Proceedings of CVPR 2022</em> </span> <br>
                        <a class="tag" href="https://floatseg.github.io/" target="_blank">project page</a><span class="tagsep"> | </span>
                        <a class="tag" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Singh_FLOAT_Factorized_Learning_of_Object_Attributes_for_Improved_Multi-Object_Multi-Part_CVPR_2022_paper.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                        <a class="tag" href="cites/float.bib" target="_blank">cite</a>
                    </p>

                    <p class="paper my-2 pl-2">
                        <span class="projecttitle">How much complexity does an RNN architecture need to learn syntax-sensitive dependencies?</span><br>
                        Gantavya Bhatt*, Hritik Bansal*, <span class="thisauthor"><b>Rishubh Singh*</b></span>, Sumeet Agrawal
                        <span class="noter"> (* = Equal Contribution)</span><br>
                        <span class="conf"><a class="confshort" href="https://acl2020.org/" target="_blank">ACL'20</a> :
                            <a class="confshort" href="https://sites.google.com/corp/view/acl20studentresearchworkshop/" target="_blank">Student Research Workshop</a> | 
                            Annual Conference of the Association for Computational Linguistics</span><br>
                            
                        <a class="tag" href="https://aclanthology.org/2020.acl-srw.33/" target="_blank">abstract</a><span class="tagsep">|</span>
                        <a class="tag" href="https://aclanthology.org/2020.acl-srw.33.pdf" target="_blank">pdf</a><span class="tagsep">|</span>
                        <a class="tag" href="cites/acl2020srw.bib" target="_blank">cite</a>
                    </p>
                 </div>


                 <p class="header pt-5">Ongoing Projects</p>
                 <div class="py-2">
                 <p class="paper my-2 pl-2">
                     <span class="projecttitle">Understanding the transfer gap between models learned from videos and images<br></span>
                        <li>Humans learn from video-style data which is believed to have better learning cues and generalize well to images.</li>
                        <li>In contrast, models learned from video data do not transfer well to image data.</li>
                        <li>Recent work has tried closing this gap by efforts in reducing distribution shift, but still need additional artificial augmentations to compete with image based methods.</li>
                        <li>Our initial experiments demonstrate a larger gap between video to image transfer than image to image transfer under distribution shifts.</li>
                        <li>Working on categorising underlying reasons and experimenting with remedies to fix them.</li>
                 </p>
                 </div>

                 <div class="py-2">
                 <p class="paper my-2 pl-2">
                     <span class="projecttitle">Object Centric Learning for Robust and Interpretable Image Classification<br></span>
                     <li>Designing object centric bottlenecks for creating robust latent representations for classification.</li>
                     <li>Creating segmentation sub-tasks for increased interpretability of the model's predictions.</li>
                     <li>Applying part based feature generation and contrastive learning via graph matching for improved generalization.</li>
                 </p>
                 </div>

                 <div class="py-2">
                    <p class="paper my-2 pl-2">
                        <span class="projecttitle">Explicit Orientation Learning for Object-Part Segmentation and Spatial Pose Understanding<br></span>
                        <li>Humans and primates have an inherent 3D understanding of the world which is built around orientation of object.</li>
                        <li>Explicitly forcing the model to learn orientation of objects and object parts through design changes improves spatial understanding and part segmentation.</li>
                    </p>
                    </div>
                 
                 </div>
            </div>

            <div class="row text-center py-4">
                <div class="mx-auto mt-2" style="width: 260px;">
                    <img class="img-fluid instilogo p-1" src="images/iitd_logo.png">
                    <div class="institution">Indian Institute of Technology, Delhi</div>
                    <div class="years">2014 - 2019</div>
                </div>
                <div class="mx-auto mt-2" style="width: 280px;">
                    <img class="img-fluid instilogo p-1" src="images/kth_logo.png">
                    <div class="institution">KTH Royal Institute of Technology, Stockholm</div>
                    <div class="years">Fall 2016</div>
                </div>
                <div class="mx-auto mt-2" style="width: 190px;">
                    <img class="img-fluid instilogo p-1" src="images/google_logo.png">
                    <div class="institution">Google, Mountain View</div>
                    <div class="years">Summers of 2017 and 2018</div>
                </div>
                <div class="mx-auto mt-2" style="width: 220px;">
                    <img class="img-fluid instilogo p-1" src="images/graviton_logo.png">
                    <div class="institution">Graviton Research Capital LLP</div>
                    <div class="years">2019 - 2020</div>
                </div>
                <div class="mx-auto mt-2" style="width: 190px;">
                    <img class="img-fluid instilogo p-3" src="images/googleresearch.png">
                    <div class="institution">Google Research India</div>
                    <div class="years">2020 - Present</div>
                </div>
                </div>
            </div>
            
        </div>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>
    <script src="assets/style-2.js"></script>
</body>
  <style>
  </style>
</html>